{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP8FMu0f4dqUURhiup4Urrk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelGallo/LLM/blob/main/LLM_An%C3%A1lise_sentimento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Projeto LLM - Análise de Sentimento**\n",
        "\n",
        "A análise de sentimento é uma área crucial no campo da inteligência artificial (IA), permitindo-nos compreender e extrair insights valiosos dos textos em diversas aplicações, desde análise de redes sociais até feedback do cliente. O Projeto LLM (Large Language Model) visa explorar essa área emocionante, utilizando técnicas de aprendizado de máquina para entender e classificar os sentimentos expressos em textos.\n",
        "\n",
        "**A) Introdução**\n",
        "Neste projeto, embarcamos em uma jornada para conhecer mais sobre os modelos generativos de IA, especificamente os modelos LLM. Os LLMs são modelos de linguagem que demonstram habilidades impressionantes na compreensão e geração de texto, impulsionados por técnicas avançadas de aprendizado de máquina.\n",
        "\n",
        "**Descrição do Projeto**\n",
        "\n",
        "1) Criação do Conjunto de Dados: Na primeira etapa, iniciamos com a criação de um conjunto de dados contendo textos aleatórios com diferentes sentimentos. Esses textos servirão como nossa base para treinar e testar os modelos.\n",
        "\n",
        "2) Classificação de Sentimentos com Naive Bayes: Utilizamos um modelo de aprendizado de máquina Naive Bayes para classificar os sentimentos presentes nos textos. Esta etapa nos proporciona uma referência inicial para comparar o desempenho dos modelos LLM.\n",
        "\n",
        "**Modelo LLM**\n",
        "\n",
        "Criação do Modelo LLM: Utilizamos modelos LLM como GPT e BART para criar um modelo capaz de compreender e gerar texto. Treinamos o modelo usando o conjunto de dados preparado anteriormente.\n",
        "\n",
        "**1) Avaliação com Matriz de Confusão:** Após treinar o modelo LLM, avaliamos seu desempenho comparando as previsões do modelo com as classificações de sentimentos reais dos textos. Utilizamos uma matriz de confusão para visualizar e analisar os resultados.\n",
        "\n",
        "**2) Clusterização de Texto:** Na última etapa, exploramos a clusterização dos textos com base nos sentimentos expressos. Utilizamos o algoritmo K-means para agrupar os textos em clusters representativos dos diferentes sentimentos."
      ],
      "metadata": {
        "id": "cIjJmqhL8AWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando pacotes\n",
        "!pip install vaderSentiment\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "uJlnmprT87gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importando bibliotecas\n",
        "import random\n",
        "import csv\n",
        "from time import time\n",
        "\n",
        "## Biblioteca manipulação arquivos csv\n",
        "import pandas as pd\n",
        "\n",
        "# Biblioteca treinamento para modelo ML\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Biblioteca para vetorização texto\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Biblioteca modelo machine learning\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Biblioteca para avaliação modelo\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "_4p93Sq2qiGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import csv\n",
        "\n",
        "# Frases de exemplo com diferentes sentimentos\n",
        "frases_neutras = [\n",
        "    \"The sky is clear and the wind blows gently.\",\n",
        "    \"The math class was about linear equations.\",\n",
        "    \"Today's lunch was rice and beans.\",\n",
        "    \"The city is quiet this Sunday.\",\n",
        "    \"The sales report will be sent by email tomorrow.\"\n",
        "]\n",
        "\n",
        "frases_positivas = [\n",
        "    \"Her smile brightens my day, bringing joy to my heart.\",\n",
        "    \"I received a compliment from my boss for the excellent work done.\",\n",
        "    \"I am very happy with the result of the test I took today.\",\n",
        "    \"Today is a beautiful day full of possibilities.\",\n",
        "    \"I received a wonderful surprise from my best friend.\"\n",
        "]\n",
        "\n",
        "frases_negativas = [\n",
        "    \"The sudden loss left a void in my chest, a pain that seems unbearable.\",\n",
        "    \"I missed my flight and now I'm stuck at the airport.\",\n",
        "    \"The traffic is terrible, and I'm late for the important meeting.\",\n",
        "    \"My computer broke down and I lost all my important files.\",\n",
        "    \"I'm sick and can't get out of bed.\"\n",
        "]\n",
        "\n",
        "# Listas para armazenar as frases geradas\n",
        "frases_geradas = []\n",
        "\n",
        "# Gerar 900 frases neutras\n",
        "for _ in range(50):\n",
        "    frase = random.choice(frases_neutras)\n",
        "    frases_geradas.append(frase)\n",
        "\n",
        "# Gerar 900 frases positivas\n",
        "for _ in range(50):\n",
        "    frase = random.choice(frases_positivas)\n",
        "    frases_geradas.append(frase)\n",
        "\n",
        "# Gerar 900 frases negativas\n",
        "for _ in range(50):\n",
        "    frase = random.choice(frases_negativas)\n",
        "    frases_geradas.append(frase)\n",
        "\n",
        "# Embaralhar as frases\n",
        "random.shuffle(frases_geradas)\n",
        "\n",
        "# Salvar as frases em um arquivo CSV\n",
        "with open(\"frases_geradas.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Frase\"])\n",
        "    writer.writerows(map(lambda x: [x], frases_geradas))\n"
      ],
      "metadata": {
        "id": "OXxWMfxxqjA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar DataFrame com Pandas\n",
        "df = pd.DataFrame(frases_geradas, columns=['Frase'])\n",
        "\n",
        "# Visualizando 5 primeiros dados\n",
        "df.head()"
      ],
      "metadata": {
        "id": "w4Nz7ulNsAX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando 5 últimos dados\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "M7Jd-no70gMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando linhas e colunas\n",
        "df.shape"
      ],
      "metadata": {
        "id": "QEx0_Tpz0gRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classificando os sentimentos das frases\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Criar uma instância do SentimentIntensityAnalyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Função para classificar as frases com base nas pontuações de sentimento\n",
        "def classify_sentiment(text):\n",
        "    scores = analyzer.polarity_scores(text)\n",
        "    if scores['compound'] > 0.5:\n",
        "        return \"positivo\"\n",
        "    elif scores['compound'] < -0.5:\n",
        "        return \"negativo\"\n",
        "    else:\n",
        "        return \"neutro\"\n",
        "\n",
        "# Aplicar a função classify_sentiment a cada frase no conjunto de dados\n",
        "df['Sentimento'] = df['Frase'].apply(classify_sentiment)\n",
        "\n",
        "# Exibir as primeiras linhas do conjunto de dados com o sentimento classificado\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PdLljDK86JBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão treino e teste\n",
        "x = df['Frase']\n",
        "y = df['Sentimento']"
      ],
      "metadata": {
        "id": "QHcqx8xGrOqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividindo os dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Visualizando os dados\n",
        "print(X_train.head())\n",
        "print(y_train.head())"
      ],
      "metadata": {
        "id": "8t3rCE0jqjDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vetorizando o texto\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "E6W89EbCqjGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinando o classificador Naive Bayes\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train_vectorized, y_train)"
      ],
      "metadata": {
        "id": "sj--8lVkqjI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazendo previsões no conjunto de teste\n",
        "predictions = classifier.predict(X_test_vectorized)"
      ],
      "metadata": {
        "id": "rC-U79uwqjLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliando a precisão do modelo\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Acurácia do modelo:\", accuracy)"
      ],
      "metadata": {
        "id": "oTTiRZVxqjOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test, predictions)\n",
        "print(\"Relatório de classificação:\")\n",
        "print(report)"
      ],
      "metadata": {
        "id": "ISYtxqH7sPiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion1 = confusion_matrix(y_test, predictions)\n",
        "print(\"Matriz de confusão:\")\n",
        "print(confusion1)"
      ],
      "metadata": {
        "id": "pffG6BnLsPma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plotar a matriz de confusão\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion1, annot=True,\n",
        "            fmt='d', cmap='Blues')\n",
        "plt.xlabel('Rótulos Previstos')\n",
        "plt.ylabel('Rótulos Verdadeiros')\n",
        "plt.title('Matriz de Confusão - Modelo Machine learning - Naive Bayes')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KZwQjRml0Iue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo LLM - Bert**"
      ],
      "metadata": {
        "id": "8bzRmUTzuMpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando biblitecas\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.optim as optim\n",
        "from torch.nn.functional import softmax\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification"
      ],
      "metadata": {
        "id": "GpTAVIo7uG_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "YC_wmDFy3qPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifique se a GPU está disponível\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Dispositivo de treinamento:\", device)"
      ],
      "metadata": {
        "id": "ldmVrQQp2qc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "zp2lQ6H6uZNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir os dados em textos e rótulos\n",
        "textos = df['Frase'].tolist()\n",
        "rotulos = df['Sentimento'].tolist()"
      ],
      "metadata": {
        "id": "ncT3Itivuc-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapeamento de rótulos de sentimentos para índices numéricos\n",
        "# Suponha que tenhamos rótulos: 'positivo', 'negativo' e 'neutro'\n",
        "mapa_rotulos = {'positivo': 0, 'negativo': 1, 'neutro': 2}\n",
        "rotulos_numericos = [mapa_rotulos[r] for r in rotulos]"
      ],
      "metadata": {
        "id": "3lyAYCxOuokn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o tokenizador e o modelo BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "biISQHfbuuVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo LLM\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(mapa_rotulos))"
      ],
      "metadata": {
        "id": "55bV7l1huuYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizar as frases\n",
        "tokens = tokenizer(textos, padding=True, truncation=True, return_tensors='pt')"
      ],
      "metadata": {
        "id": "MjnPvQZbu08H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar DataLoader para iterar sobre os dados durante o treinamento\n",
        "dataset = TensorDataset(tokens.input_ids, tokens.attention_mask, torch.tensor(rotulos_numericos))\n",
        "\n",
        "# Se você estiver usando um DataLoader, você precisa especificar o argumento `pin_memory=True`\n",
        "loader = DataLoader(dataset, batch_size=8, shuffle=True, pin_memory=True)"
      ],
      "metadata": {
        "id": "U36q-4xYu46R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mova o modelo e os dados para o mesmo dispositivo\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "ucMWS36cu5ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defina o otimizador\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "OQUHYwG33Ew6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop de treinamento\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    print(f'Época {epoch + 1}')\n",
        "    for input_ids, attention_mask, labels in loader:\n",
        "        # Mova os dados para o mesmo dispositivo que o modelo\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        predictions = torch.argmax(outputs.logits, dim=1)\n",
        "        print(\"Previsões:\", predictions)\n",
        "    print(f'Perda Total: {total_loss:.2f}')"
      ],
      "metadata": {
        "id": "wcGVR1o-vjeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mova o modelo para o mesmo dispositivo\n",
        "model = model.to(device)\n",
        "\n",
        "# Inicialize as listas para armazenar as previsões e os rótulos verdadeiros\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# Loop de treinamento\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    print(f'Época {epoch + 1}')\n",
        "    for input_ids, attention_mask, labels in loader:\n",
        "        # Mova os dados para o mesmo dispositivo que o modelo\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            predictions.extend(torch.argmax(outputs.logits, dim=1).tolist())\n",
        "            true_labels.extend(labels.tolist())"
      ],
      "metadata": {
        "id": "nNN5_tXBvQi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir previsões e rótulos\n",
        "print(\"Previsões:\", predictions)\n",
        "print(\"Rótulos verdadeiros:\", true_labels)"
      ],
      "metadata": {
        "id": "_umHf5Ii5nFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular a matriz de confusão\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "# Plotar a matriz de confusão\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True,\n",
        "            fmt='d', cmap='Blues',\n",
        "            xticklabels=mapa_rotulos.keys(),\n",
        "            yticklabels=mapa_rotulos.keys())\n",
        "\n",
        "# Legenda gráfico\n",
        "plt.xlabel('Rótulos Previstos')\n",
        "plt.ylabel('Rótulos Verdadeiros')\n",
        "plt.title('Matriz de Confusão - Modelo LLM Bert')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KCZ09RZXvYg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o modelo treinado\n",
        "model.save_pretrained('modelo_sentimentos_bert')"
      ],
      "metadata": {
        "id": "LI2WekGRv35x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modelo LLM 2 - EleutherAI/gpt-neo-125M**"
      ],
      "metadata": {
        "id": "g3duSZxawlrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "PRmJ5kYuK6zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas\n",
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer"
      ],
      "metadata": {
        "id": "iA8LezEmwqPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o modelo e o tokenizador\n",
        "model_name = \"EleutherAI/gpt-neo-125M\""
      ],
      "metadata": {
        "id": "hPnIqJFkwvtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizado\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "xBXAOBHzww3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo\n",
        "model = GPTNeoForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "x3Xga8ghwzHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transferir o modelo para a GPU, se disponível\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "qbQYFAiaIg6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para gerar texto condicionado ao sentimento\n",
        "def generate_conditioned_text(text, sentiment, max_length=50):\n",
        "\n",
        "    input_text = f\"{text} <SENTIMENT> {sentiment}\"\n",
        "\n",
        "    input_ids = tokenizer.encode(input_text,\n",
        "                                 return_tensors=\"pt\",\n",
        "                                 max_length=max_length,\n",
        "                                 truncation=True).to(device)\n",
        "\n",
        "    output = model.generate(input_ids,\n",
        "                            max_length=max_length,\n",
        "                            pad_token_id=tokenizer.eos_token_id).to(device)\n",
        "\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Definir o número de épocas\n",
        "num_epocas = 3\n",
        "\n",
        "# Sentimentos para condicionar o texto gerado\n",
        "sentimentos = [\"positivo\", \"negativo\", \"neutro\"]\n",
        "\n",
        "# Tempo de início\n",
        "start_time = time()\n",
        "\n",
        "# Gerar previsões de sentimentos para cada texto\n",
        "previsoes = []\n",
        "\n",
        "# Contador para acompanhar o número de iterações\n",
        "iteracao = 0\n",
        "\n",
        "# Loop para cada época\n",
        "for epoch in range(num_epocas):\n",
        "    print(f\"Época {epoch + 1}/{num_epocas}\")\n",
        "\n",
        "    # Loop para cada texto\n",
        "    for texto in df['Frase']:\n",
        "        for sentimento in sentimentos:\n",
        "            iteracao += 1\n",
        "            print(f\"Iteração {iteracao}\")\n",
        "\n",
        "            # Gerar texto condicionado ao sentimento\n",
        "            texto_gerado = generate_conditioned_text(texto, sentimento)\n",
        "            previsoes.append((texto, sentimento, texto_gerado))  # Armazenar o texto original, sentimento e o texto gerado\n",
        "            print(f\"Texto original: {texto}\")\n",
        "            print()\n",
        "            print(f\"Sentimento: {sentimento}\")\n",
        "            print()\n",
        "            print(f\"Texto gerado: {texto_gerado}\")\n"
      ],
      "metadata": {
        "id": "jONdP6mTw_IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar DataFrame a partir das previsões\n",
        "df_resultados = pd.DataFrame(previsoes,\n",
        "                             columns=['Texto',\n",
        "                                      'Sentimento',\n",
        "                                      'Texto_Gerado'])\n",
        "\n",
        "# Adicionar a coluna Sentimento\n",
        "df_resultados.head()"
      ],
      "metadata": {
        "id": "YXC7RLdGMBn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o DataFrame em um arquivo CSV\n",
        "df_resultados.to_csv(\"resultados_llm.csv\", index=False)"
      ],
      "metadata": {
        "id": "GmW0Ovmb1L41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Clusterização os sentimentos com LLM**"
      ],
      "metadata": {
        "id": "djIXOMvDxZoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "data = pd.read_csv(\"resultados_llm.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "dmKHMnYC2P8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir os dados em textos e rótulos\n",
        "textos = data['Texto_Gerado'].tolist()\n",
        "rotulos = data['Sentimento'].tolist()"
      ],
      "metadata": {
        "id": "XVUhgi3yz6lA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vetorização dos textos usando TF-IDF\n",
        "\n",
        "# Importando biblioteca\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Defina o número máximo de features conforme necessário\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Treinamento modelo\n",
        "X = vectorizer.fit_transform(data['Texto_Gerado'])"
      ],
      "metadata": {
        "id": "sWbCe3wFxZFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando biblioteca\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Calcular a inércia para diferentes valores de k\n",
        "inertia = []\n",
        "for k in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plotar o gráfico Elbow\n",
        "plt.plot(range(1, 11), inertia, marker='o')\n",
        "plt.xlabel('Número de clusters')\n",
        "plt.ylabel('Inércia')\n",
        "plt.title('Método Elbow para encontrar o número ideal de clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H6JKLQHjxZMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando biblioteca\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Defina o número ideal de clusters obtido a partir do método Elbow\n",
        "k = 4\n",
        "\n",
        "# Criar e ajustar o modelo K-means\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "\n",
        "# Treinamento modelo\n",
        "kmeans.fit(X)"
      ],
      "metadata": {
        "id": "eo1NYoByxZPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obter os rótulos de cluster para cada amostra\n",
        "labels = kmeans.labels_"
      ],
      "metadata": {
        "id": "dRKtwkh201vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicionar os rótulos de cluster de volta ao dataframe original\n",
        "data['Cluster'] = labels\n",
        "\n",
        "# Visualizando\n",
        "data.head()"
      ],
      "metadata": {
        "id": "qdmrk2Sy01xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Modelo PCA\n",
        "\n",
        "# Importando bibliotecas\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Reduzir a dimensionalidade para visualização\n",
        "pca = PCA(n_components=5)\n",
        "\n",
        "# Treinamento\n",
        "X_pca = pca.fit_transform(X.toarray())\n",
        "\n",
        "# Visualizando\n",
        "pca"
      ],
      "metadata": {
        "id": "tDbNGQFrGftM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar os clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], cmap='viridis')\n",
        "\n",
        "# Adicionar a legenda manualmente\n",
        "for sentimento, cor in colors.items():\n",
        "    plt.scatter([], [], color=cor, label=sentimento)\n",
        "\n",
        "plt.title('Gráfico de Clusterização sentimentos LLM')\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.legend(title='Sentimento')\n",
        "plt.colorbar(label='Sentimento')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3vuqa2tEj4_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusão**\n",
        "\n",
        "Este projeto oferece uma introdução valiosa ao fascinante mundo dos modelos LLM e sua aplicação na análise de sentimento. Ao longo do projeto, ganhamos insights sobre como os modelos de linguagem podem ser usados para compreender e interpretar o contexto emocional dos textos. Este é apenas o primeiro passo em nossa jornada de exploração no campo da inteligência artificial e aprendizado de máquina."
      ],
      "metadata": {
        "id": "Lw8A85q6nazm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JESnCGrgnfnQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}