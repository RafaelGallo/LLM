{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLZqslkQ8v3luKO8vkEWLM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelGallo/LLM/blob/main/LLM_Cluster_kmeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando bibliotecas geral\n",
        "!pip install nltk\n",
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "id": "HkmWRSKoOkh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9M1fsfPFKrJe"
      },
      "outputs": [],
      "source": [
        "# Importando bibliotecas\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# English positive phrases\n",
        "positive_phrases = [\n",
        "    \"I love summer!\",\n",
        "    \"This movie is amazing.\",\n",
        "    \"I'm very happy today.\",\n",
        "    \"I enjoy spending time with my family.\",\n",
        "    \"I got a promotion at work, I'm ecstatic!\"\n",
        "]\n",
        "\n",
        "# English neutral phrases\n",
        "neutral_phrases = [\n",
        "    \"The weather is nice today.\",\n",
        "    \"This is a cup of coffee.\",\n",
        "    \"I'm going to work now.\",\n",
        "    \"Her phone number is 123-456-7890.\",\n",
        "    \"The food is ready.\"\n",
        "]\n",
        "\n",
        "# English negative phrases\n",
        "negative_phrases = [\n",
        "    \"I'm feeling sad.\",\n",
        "    \"I don't like horror movies.\",\n",
        "    \"The traffic is terrible today.\",\n",
        "    \"I had a very stressful day.\",\n",
        "    \"I think I'm sick.\"\n",
        "]\n",
        "\n",
        "# Random samples from each category\n",
        "phrases = np.random.choice(positive_phrases, 900).tolist() + np.random.choice(neutral_phrases, 900).tolist() + np.random.choice(negative_phrases, 900).tolist()\n",
        "\n",
        "# Create a DataFrame with the phrases\n",
        "df = pd.DataFrame({'Frases': phrases})\n",
        "\n",
        "# Shuffle the rows\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Salvar os dados em um arquivo CSV\n",
        "df.to_csv('base_de_dados.csv', index=False)\n",
        "\n",
        "# Visualizar as primeiras linhas do DataFrame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "K_VgTmlPK017"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "9Ubjqi9nf9kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "vw7nVfobf--O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Devisão\n",
        "train = df['Frases']"
      ],
      "metadata": {
        "id": "LhdfrO-kLFua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vetorizar as frases usando TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Treinamento modelo\n",
        "X_texto = vectorizer.fit_transform(df['Frases'])"
      ],
      "metadata": {
        "id": "7DGPRWflLPds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determinando o número ideal de clusters usando método Elbow\n",
        "inertia_values = []\n",
        "silhouette_scores = []\n",
        "max_clusters = 15  # Você pode ajustar esse valor conforme necessário\n",
        "\n",
        "for k in range(2, max_clusters + 1):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_texto)\n",
        "    inertia_values.append(kmeans.inertia_)\n",
        "    if k > 1:\n",
        "        silhouette_scores.append(silhouette_score(X_texto, kmeans.labels_))\n",
        "\n",
        "# Plotando o gráfico do método Elbow\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(2, max_clusters + 1), inertia_values, marker='o')\n",
        "plt.xlabel('Número de Clusters')\n",
        "plt.ylabel('Inércia')\n",
        "plt.title('Método Elbow')\n",
        "\n",
        "# Plotando o gráfico da métrica de Silhouette\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(2, max_clusters + 1), silhouette_scores, marker='o')\n",
        "plt.xlabel('Número de Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3NsLWlYwjc0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo kmeans\n",
        "\n",
        "# Usando o número ideal de clusters determinado pelo método Elbow\n",
        "# Você pode ajustar esse valor conforme necessário\n",
        "numero_clusters = 4\n",
        "\n",
        "# Criando o modelo KMeans\n",
        "modelo_kmeans = KMeans(n_clusters=numero_clusters, random_state=42)\n",
        "modelo_kmeans.fit(X_texto)"
      ],
      "metadata": {
        "id": "Yv20yTEyLpwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicionar os rótulos de cluster ao DataFrame\n",
        "df['cluster'] = modelo_kmeans.labels_\n",
        "df.head()"
      ],
      "metadata": {
        "id": "OTqohRtTQ40Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtendo os rótulos dos clusters para as palavras\n",
        "rotulos_clusters = modelo_kmeans.labels_\n",
        "\n",
        "# Imprimindo os rótulos dos clusters para cada palavra\n",
        "for palavra, cluster in zip(X_texto, rotulos_clusters):\n",
        "    print(f\"{palavra}: Cluster {cluster}\")"
      ],
      "metadata": {
        "id": "1nKOC4ZOLt7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Reduzindo a dimensionalidade dos dados para 2D usando PCA\n",
        "pca = PCA(n_components=5, random_state=42)\n",
        "X_reduced = pca.fit_transform(X_texto.toarray())\n",
        "\n",
        "# Visualizando modelo\n",
        "pca"
      ],
      "metadata": {
        "id": "QWEUQMgSLyf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotando os clusters\n",
        "plt.figure(figsize=(8, 6))\n",
        "for cluster_num in range(numero_clusters):\n",
        "    plt.scatter(X_reduced[rotulos_clusters == cluster_num, 0],\n",
        "                X_reduced[rotulos_clusters == cluster_num, 1],\n",
        "                label=f'Cluster {cluster_num}')\n",
        "\n",
        "plt.title('Clusters palavras com Kmeans')\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.legend()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rWnqnbpiL5V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vetorizando as frases usando TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Treinamento\n",
        "train = vectorizer.fit_transform(df['Frases'])\n",
        "\n",
        "# Visualizando modelo\n",
        "vectorizer"
      ],
      "metadata": {
        "id": "vS0j6nkPMSLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo t_SNE\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Aplicando t-SNE para redução de dimensionalidade\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "\n",
        "# Treinamento modelo\n",
        "X_tsne = tsne.fit_transform(train.toarray())\n",
        "\n",
        "# Visualizando modelo\n",
        "tsne"
      ],
      "metadata": {
        "id": "wfIjWJufMBp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar um gráfico de dispersão com legenda baseada nos clusters\n",
        "plt.figure(figsize=(10, 8))\n",
        "for cluster_num in sorted(df['cluster'].unique()):  # Iterar sobre os clusters únicos\n",
        "    indices = df['cluster'] == cluster_num\n",
        "    plt.scatter(X_tsne[indices, 0],\n",
        "                X_tsne[indices, 1],\n",
        "                alpha=0.5,\n",
        "\n",
        "                label=f'Cluster {cluster_num}')\n",
        "\n",
        "plt.title('Visualização de Frases usando t-SNE')\n",
        "plt.xlabel('Componente 1')\n",
        "plt.ylabel('Componente 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W_E-lmsiMXQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2) Análise de sentimento com VADER**"
      ],
      "metadata": {
        "id": "oXdg3fOYOJCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualizando os dados\n",
        "\n",
        "# Visualizando os 5 primeiros dados\n",
        "df.head()"
      ],
      "metadata": {
        "id": "BOQF2bR8OIoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando linhas e colunas\n",
        "df.shape"
      ],
      "metadata": {
        "id": "DPuWqYAzOP1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando análise de sentimendo com vader\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Inicialize o analisador de sentimentos\n",
        "analisador = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Função para calcular o sentimento de uma frase\n",
        "def analisar_sentimento(frase):\n",
        "    return analisador.polarity_scores(frase)['compound']\n",
        "\n",
        "# Aplicar a função de análise de sentimento à coluna 'frases'\n",
        "df['polaridade'] = df['Frases'].apply(analisar_sentimento)\n",
        "\n",
        "# Função para categorizar o sentimento\n",
        "def categorizar_sentimento(compound):\n",
        "    if compound > 0.05:\n",
        "        return 'positivo'\n",
        "    elif compound < -0.05:\n",
        "        return 'negativo'\n",
        "    else:\n",
        "        return 'neutro'\n",
        "\n",
        "# Função para calcular o sentimento de uma frase e categorizá-la\n",
        "def analisar_sentimento(frase):\n",
        "    compound = analisador.polarity_scores(frase)['compound']\n",
        "    return categorizar_sentimento(compound)\n",
        "\n",
        "# Aplicar a função de análise de sentimento e categorização à coluna 'frases'\n",
        "df['sentimento'] = df['Frases'].apply(analisar_sentimento)\n",
        "\n",
        "# Exibir o DataFrame com as pontuações de sentimento\n",
        "df.head()"
      ],
      "metadata": {
        "id": "U0pV_C7lPAyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='sentimento', data=df)\n",
        "plt.title('Distribuição de Sentimentos')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6UrQ-P-7er-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x='sentimento', y='polaridade', hue=\"sentimento\", data=df)\n",
        "plt.title('Distribuição de Polaridade por Sentimento')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TAEwuF5nesE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(df['polaridade'], kde=True)\n",
        "plt.title('Distribuição de Polaridade')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eZ02fLzcfAed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3) Sentimento com PCA**"
      ],
      "metadata": {
        "id": "mHvPn9-YWfJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir o DataFrame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "CkB44pBuWRlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando biblioteca\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Vetorizar as frases usando TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Treinamento\n",
        "X_texto = vectorizer.fit_transform(df['Frases'])\n",
        "\n",
        "# Visualizando\n",
        "vectorizer"
      ],
      "metadata": {
        "id": "r3HjGAKcWne_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar DataFrame para as características de texto\n",
        "X_texto_df = pd.DataFrame(X_texto.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Mapear valores categóricos da coluna 'sentimento' para números\n",
        "sentimento_numerico = {'positivo': 1, 'neutro': 0, 'negativo': -1}\n",
        "df['sentimento_numerico'] = df['sentimento'].map(sentimento_numerico)\n",
        "\n",
        "# Concatenar as características de texto com a coluna 'sentimento_numerico'\n",
        "X = pd.concat([X_texto_df, df[['sentimento_numerico']]], axis=1)"
      ],
      "metadata": {
        "id": "YAM7eacwW5F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Padronizar os dados\n",
        "scaler = StandardScaler()\n",
        "X_padronizado = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "iZ92ALJOWSsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo PCA\n",
        "\n",
        "# Defina o número de componentes desejado\n",
        "numero_componentes = 2\n",
        "\n",
        "# Modelo PCA\n",
        "pca = PCA(n_components=numero_componentes, random_state=42)\n",
        "\n",
        "# Treinamento modelo\n",
        "X_reduzido = pca.fit_transform(X_padronizado)\n",
        "\n",
        "# Visualizando modelo\n",
        "pca"
      ],
      "metadata": {
        "id": "mdXyD8mKWyir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar um DataFrame com os componentes principais e a coluna de sentimento\n",
        "df_pca = pd.DataFrame(X_reduzido, columns=['Componente 1', 'Componente 2'])\n",
        "df_pca['sentimento'] = df['sentimento']\n",
        "\n",
        "# Visualizando modelo PCA\n",
        "df_pca.head()"
      ],
      "metadata": {
        "id": "el8KOkUNYRy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar o gráfico PCA com legenda\n",
        "cores = {'positivo': 'blue',\n",
        "         'neutro': 'gray',\n",
        "         'negativo': 'red'}\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "for sentimento, cor in cores.items():\n",
        "    indices = df_pca['sentimento'] == sentimento\n",
        "    plt.scatter(df_pca.loc[indices, 'Componente 1'],\n",
        "                df_pca.loc[indices, 'Componente 2'],\n",
        "                color=cor,\n",
        "                label=sentimento)\n",
        "\n",
        "plt.title('PCA com legenda dos sentimentos')\n",
        "plt.xlabel('Componente 1')\n",
        "plt.ylabel('Componente 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jh_HDiL0X1G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo 2 - t_SNE"
      ],
      "metadata": {
        "id": "9dxcUouAYFXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vetorizar as frases usando TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_texto = vectorizer.fit_transform(df['Frases'])"
      ],
      "metadata": {
        "id": "8dsSLKbiYhlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar o t-SNE para redução de dimensionalidade\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "\n",
        "# Treinamento\n",
        "X_tsne = tsne.fit_transform(X_padronizado)\n",
        "\n",
        "# Visualizando modelo\n",
        "tsne"
      ],
      "metadata": {
        "id": "nr4b5Jx2Yh7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir cores para cada categoria de sentimento\n",
        "cores = {'positivo': 'blue',\n",
        "         'neutro': 'gray',\n",
        "         'negativo': 'red'}\n",
        "\n",
        "# Plotar o gráfico de dispersão com legendas\n",
        "plt.figure(figsize=(10, 8))\n",
        "for sentimento, cor in cores.items():\n",
        "    indices = df['sentimento'] == sentimento\n",
        "    plt.scatter(X_tsne[indices, 0], X_tsne[indices, 1], alpha=0.5, color=cor, label=sentimento)\n",
        "\n",
        "plt.title('Visualização de Frases usando t-SNE com Sentimentos')\n",
        "plt.xlabel('Componente 1')\n",
        "plt.ylabel('Componente 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qe0y7ed9Yh-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4) LLM**\n",
        "\n",
        "## Modelo 1) EleutherAI/gpt-neo-125M"
      ],
      "metadata": {
        "id": "8h6_V8linm6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# base dados\n",
        "# Frases com sentimentos positivos\n",
        "frases_positivas = [\n",
        "    \"I love spending time with my family.\",\n",
        "    \"The weather is beautiful today.\",\n",
        "    \"I feel happy when I'm with my friends.\",\n",
        "    \"I accomplished my goals for today.\"\n",
        "]\n",
        "\n",
        "# Frases com sentimentos negativos\n",
        "frases_negativas = [\n",
        "    \"I'm feeling sad and lonely.\",\n",
        "    \"The news about the accident was heartbreaking.\",\n",
        "    \"I failed my exam and I'm disappointed in myself.\",\n",
        "    \"I had a terrible day at work.\"\n",
        "]\n",
        "\n",
        "# Frases com sentimentos neutros\n",
        "frases_neutras = [\n",
        "    \"The cat is sleeping on the couch.\",\n",
        "    \"I'm going to the grocery store later.\",\n",
        "    \"Today is Monday.\",\n",
        "    \"I have to finish my report by tomorrow.\"\n",
        "]\n",
        "\n",
        "# Criar uma lista com todas as frases e seus respectivos sentimentos\n",
        "frases = []\n",
        "sentimentos = []\n",
        "\n",
        "# Adicionar frases positivas\n",
        "for frase in frases_positivas:\n",
        "    frases.append(frase)\n",
        "    sentimentos.append(\"positivo\")\n",
        "\n",
        "# Adicionar frases negativas\n",
        "for frase in frases_negativas:\n",
        "    frases.append(frase)\n",
        "    sentimentos.append(\"negativo\")\n",
        "\n",
        "# Adicionar frases neutras\n",
        "for frase in frases_neutras:\n",
        "    frases.append(frase)\n",
        "    sentimentos.append(\"neutro\")\n",
        "\n",
        "# Embaralhar as frases\n",
        "indices_embaralhados = list(range(len(frases)))\n",
        "random.shuffle(indices_embaralhados)\n",
        "\n",
        "# Criar o DataFrame\n",
        "df = pd.DataFrame({'Frase': [frases[i] for i in indices_embaralhados]})\n",
        "\n",
        "# Exibir as primeiras linhas do DataFrame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "7NVKsgAw_PmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando biblioteca\n",
        "from transformers import pipeline\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "acMj51UFYiAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o modelo e o tokenizador\n",
        "model_name = \"EleutherAI/gpt-neo-125M\"\n",
        "\n",
        "# Carregar o modelo pré-treinado GPT-2\n",
        "modelo = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "J8GfGikoYiC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenização modelo\n",
        "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Modelo\n",
        "model = AutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "VzR6w3jsn5sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenar todas as frases em uma única string\n",
        "frases_concatenadas = \" \".join(df['Frase'].tolist())"
      ],
      "metadata": {
        "id": "cXBVGNXNoDH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizar a string de frases\n",
        "tokens = tokenizer.encode(frases_concatenadas, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "8ZKzkMz0orvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para gerar texto continuando a sequência de uma única frase\n",
        "def gerar_texto(frase):\n",
        "    tokens = tokenizer.encode(frase, return_tensors=\"pt\")\n",
        "    outputs = modelo.generate(tokens, max_length=20, num_return_sequences=1, early_stopping=True)\n",
        "    texto_gerado = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return texto_gerado\n",
        "\n",
        "# Gerar texto para cada frase no DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    frase = row['Frase']\n",
        "    texto_gerado = gerar_texto(frase)\n",
        "    print(f\"Frase original: {frase}\")\n",
        "    print()\n",
        "    print()\n",
        "    print(f\"Texto gerado: {texto_gerado}\\n\")"
      ],
      "metadata": {
        "id": "lIYZaWRtovoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvando texto em dataframe\n",
        "# Lista para armazenar os textos gerados\n",
        "textos_gerados = []\n",
        "\n",
        "# Gerar texto para cada frase no DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    frase = row['Frase']\n",
        "    texto_gerado = gerar_texto(frase)\n",
        "    textos_gerados.append(texto_gerado)\n",
        "\n",
        "# Criar um novo DataFrame com os textos gerados\n",
        "df_textos_gerados = pd.DataFrame({'Frase Original': df['Frase'],\n",
        "                                  'Texto Gerado': textos_gerados})\n",
        "\n",
        "# Salvar o DataFrame em um arquivo CSV\n",
        "df_textos_gerados.to_csv('textos_gerados.csv', index=False)"
      ],
      "metadata": {
        "id": "KgbAL_IApVoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando dataframe\n",
        "df_textos_gerados.head()"
      ],
      "metadata": {
        "id": "jSdOAtw_rMZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "uIHQ6QxuptLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando biblioteca\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Inicializar o modelo LLM\n",
        "modelo_llm = SentenceTransformer('distilbert-base-nli-mean-tokens')"
      ],
      "metadata": {
        "id": "3IksQvXPpkyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerar representações vetoriais para as frases\n",
        "representacoes = modelo_llm.encode(df['Frase'], show_progress_bar=True)"
      ],
      "metadata": {
        "id": "a1gHJFyDqF3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o pipeline para análise de sentimento\n",
        "analisador_sentimento = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "nOyHFlEGBBbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar análise de sentimento para cada frase\n",
        "for frase in frases:\n",
        "    resultado = analisador_sentimento(frase)\n",
        "    sentimento = resultado[0]['label']\n",
        "    if sentimento == 'POSITIVE':\n",
        "        print(f\"Frase: {frase}\")\n",
        "        print(\"Sentimento: Positivo\\n\")\n",
        "    elif sentimento == 'NEGATIVE':\n",
        "        print(f\"Frase: {frase}\")\n",
        "        print(\"Sentimento: Negativo\\n\")\n",
        "    else:\n",
        "        print(f\"Frase: {frase}\")\n",
        "        print(\"Sentimento: Neutro\\n\")"
      ],
      "metadata": {
        "id": "s_j3LA6iBBhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Usar o método Elbow para encontrar o número ideal de clusters\n",
        "visualizador = KElbowVisualizer(KMeans(),\n",
        "                                k=(2, 10),\n",
        "                                metric='distortion',\n",
        "                                timings=False)\n",
        "# Treinamento\n",
        "visualizador.fit(representacoes)\n",
        "\n",
        "# Visualizando\n",
        "visualizador.show()"
      ],
      "metadata": {
        "id": "CwCJxrHVqGGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obter o número ideal de clusters\n",
        "numero_clusters = visualizador.elbow_value_\n",
        "\n",
        "# Criar o modelo KMeans com o número ideal de clusters\n",
        "modelo_kmeans = KMeans(n_clusters=numero_clusters, random_state=42)\n",
        "\n",
        "# Treinar o modelo\n",
        "clusters = modelo_kmeans.fit_predict(representacoes)\n",
        "\n",
        "# Visualizando\n",
        "modelo_kmeans"
      ],
      "metadata": {
        "id": "Er_w88_SqJ7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicionar os clusters de volta ao DataFrame\n",
        "df['Cluster_LLM'] = clusters\n",
        "\n",
        "# Visualizando\n",
        "df.head()"
      ],
      "metadata": {
        "id": "cx9q2eJRqJ-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar o gráfico\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(representacoes[:, 0],\n",
        "            representacoes[:, 1],\n",
        "            c=clusters,\n",
        "            cmap='viridis')\n",
        "plt.title('Clusters LLM')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rh1GvEdMqJfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA Modelo\n",
        "# Vetorizar os textos gerados usando TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df_textos_gerados['Texto Gerado'])"
      ],
      "metadata": {
        "id": "nR8CHLzesdqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduzir a dimensionalidade com PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X.toarray())"
      ],
      "metadata": {
        "id": "RgTcXBGFsd2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicionar as componentes PCA de volta ao DataFrame\n",
        "df_textos_gerados['PCA Component 1'] = X_pca[:, 0]\n",
        "df_textos_gerados['PCA Component 2'] = X_pca[:, 1]\n",
        "\n",
        "# Plotar o gráfico\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(df_textos_gerados['PCA Component 1'], df_textos_gerados['PCA Component 2'])\n",
        "plt.title('PCA Plot dos Textos Gerados')\n",
        "plt.xlabel('Componente 1')\n",
        "plt.ylabel('Componente 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "96ZH5qJnsd5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fFgnz6CWsd8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gXDXOgMQqGJE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}